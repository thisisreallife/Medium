{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONQPR5QyLlwPYuSzgX+dgq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisisreallife/Medium/blob/master/Bias_Variance_Decoposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FE5KymhedL99"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.evaluate import bias_variance_decomp\n",
        "from mlxtend.data import boston_housing_data"
      ],
      "metadata": {
        "id": "Mg7buPTCfxNu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# Suppress scikit-learn deprecation warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "1RuW3UNdhTxi"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这篇文档主要是描述方差和偏差分解, 假设有待估参数$\\theta$, 我们的估计量是$\\hat{\\theta}$, 如果用均方误差来刻画估计的准确性, 可以把均方误差拆分为偏差和方差两部分.\n",
        "$$ MSE(\\hat{\\theta};\\theta) = E[(\\hat{\\theta} - \\theta)^2]\\\\\n",
        "= E[(\\hat{\\theta} - E(\\hat\\theta) + E(\\hat\\theta) - \\theta)^2]\\\\\n",
        "= E[(\\hat{\\theta} - E(\\hat\\theta))^2 + (E(\\hat\\theta) - \\theta)^2 + 2(\\hat{\\theta} - E(\\hat\\theta))(E(\\hat\\theta) - \\theta)]$$"
      ],
      "metadata": {
        "id": "yn7Wfg_ehxDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic Data"
      ],
      "metadata": {
        "id": "yIoZsLiBdVaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate 1000 samples with 5 numeric features\n",
        "n_samples = 10000\n",
        "X = pd.DataFrame(np.random.randn(n_samples, 5), columns=['x1', 'x2', 'x3', 'x4', 'x5'])\n",
        "\n",
        "# Define Y as a non-linear function of the features + noise\n",
        "Y = (\n",
        "    10 * X['x1'] +\n",
        "    5 * X['x2']**2 +\n",
        "    3 * X['x3'] * X['x4'] +\n",
        "    np.exp(X['x5']) +\n",
        "    np.random.normal(0, 10, n_samples)  # Noise\n",
        ")"
      ],
      "metadata": {
        "id": "3tLVgTOafXUY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias Variance Decomposition"
      ],
      "metadata": {
        "id": "mDN_c3dKfkbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting Reduces Bias, Bagging Reduces Variance: Explanation\n",
        "\n",
        "1. Bagging Reduces Variance\n",
        "Mechanism:\n",
        "\n",
        "Trains multiple models (e.g., decision trees) independently on bootstrapped subsets of the data.\n",
        "\n",
        "Predictions are averaged (regression) or majority-voted (classification).\n",
        "\n",
        "Why Variance Decreases:\n",
        "\n",
        "High-variance models (e.g., deep trees) overfit to noise in individual subsets.\n",
        "\n",
        "Averaging predictions cancels out \"noise\" across models, stabilizing the final prediction.\n",
        "\n",
        "Example:\n",
        "Random Forest averages predictions from many uncorrelated trees.\n",
        "\n",
        "2. Boosting Reduces Bias\n",
        "Mechanism:\n",
        "\n",
        "Trains models sequentially, where each new model corrects errors of previous ones.\n",
        "\n",
        "Misclassified instances are reweighted to focus on hard-to-predict cases.\n",
        "\n",
        "Why Bias Decreases:\n",
        "\n",
        "Weak learners (e.g., shallow trees) start with high bias (underfitting).\n",
        "\n",
        "Sequential correction improves approximation of the true relationship in the data.\n",
        "\n",
        "Example:\n",
        "Gradient Boosting iteratively fits residuals (errors) of prior models.\n",
        "\n",
        "3. Key Differences\n",
        "Aspect\tBagging\tBoosting\n",
        "Training\tParallel (models independent)\tSequential (models dependent)\n",
        "Focus\tReduce overfitting (variance)\tReduce underfitting (bias)\n",
        "Base Models\tHigh-variance (e.g., deep trees)\tHigh-bias (e.g., stumps)\n",
        "Prediction\tAverage/majority vote\tWeighted sum of model outputs\n",
        "4. Mathematical Intuition\n",
        "Bias-Variance Decomposition:\n",
        "\n",
        "Total Error = Bias\n",
        "2+Variance+Irreducible Error\n",
        "\n",
        "Bagging:\n",
        "\n",
        "Reduces\n",
        "Variance\n",
        "Variance through averaging:\n",
        "$Var\n",
        "(\n",
        "1\n",
        "N\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "N\n",
        "f\n",
        "i\n",
        "(\n",
        "x\n",
        ")\n",
        ")\n",
        "≈\n",
        "1\n",
        "N\n",
        "Var\n",
        "(\n",
        "f\n",
        "(\n",
        "x\n",
        ")\n",
        ")\n",
        "Var(\n",
        "N\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "N\n",
        "​\n",
        " f\n",
        "i\n",
        "​\n",
        " (x))≈\n",
        "N\n",
        "1\n",
        "​\n",
        " Var(f(x))$\n",
        "\n",
        "\n",
        "Boosting:\n",
        "\n",
        "Reduces\n",
        "Bias\n",
        "2\n",
        "Bias\n",
        "2\n",
        "  by iteratively minimizing residuals (e.g., gradient descent in function space).\n",
        "\n",
        "5. Practical Tradeoffs\n",
        "Boosting Risks:\n",
        "\n",
        "Overfitting if iterations are excessive (increasing variance).\n",
        "\n",
        "Bagging Limits:\n",
        "\n",
        "Fails to reduce bias if base models are too simple.\n",
        "\n",
        "6. Example Workflow\n",
        "python\n",
        "# Bagging (Random Forest)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "bagging_model = RandomForestRegressor(n_estimators=100, max_depth=10)  # Reduces variance\n",
        "\n",
        "# Boosting (Gradient Boosting)\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "boosting_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)  # Reduces bias\n",
        "7. When to Use Which\n",
        "Use bagging if:\n",
        "\n",
        "Your model overfits (high validation error).\n",
        "\n",
        "Base learners are high-variance (e.g., deep decision trees).\n",
        "\n",
        "Use boosting if:\n",
        "\n",
        "Your model underfits (high training error).\n",
        "\n",
        "Base learners are high-bias (e.g., shallow trees).\n",
        "\n",
        "By leveraging these mechanisms, you can systematically address bias or variance issues in your models."
      ],
      "metadata": {
        "id": "EHg3Igguv_iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bootstrapping rounds\n",
        "M  = 100\n",
        "for i in range(M):\n",
        ""
      ],
      "metadata": {
        "id": "mmffJpVchfem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OqoVMqDjJE_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cze-7wHkkTTt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTIHDTJpkikY"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_bagging = RandomForestRegressor(n_estimators = 1)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_bagging, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS2KxgB8lPue",
        "outputId": "1a2029b5-50ef-44a7-f3bc-cff90f523852"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 36.068\n",
            "Average bias: 15.440\n",
            "Average variance: 20.627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_bagging = RandomForestRegressor(n_estimators = 10,n_jobs = -1)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_bagging, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miX_qniklFg3",
        "outputId": "47c2d71b-5d22-4b9c-fd63-f3b3bc04f46b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 19.848\n",
            "Average bias: 15.158\n",
            "Average variance: 4.690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_bagging = RandomForestRegressor(n_estimators = 100, n_jobs = -1)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_bagging, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TZBkX2zjQma",
        "outputId": "97f1797c-8709-495a-9e3f-b52dc186e667"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 18.718\n",
            "Average bias: 15.527\n",
            "Average variance: 3.191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_bias**2 + avg_var**2 , avg_expected_loss**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnliDQvekSF_",
        "outputId": "bfc366d3-2f0f-489c-88a5-47e48f297988"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(248.18593771160886), np.float64(350.74220778291203))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([[1,2,3], [4,5,6]]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxXvD0cSldWF",
        "outputId": "35c682bc-29e7-47d3-ec17-10e139a5f8fb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 1, learning_rate = 0.01)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2crscd1hf_r",
        "outputId": "980f0207-0af4-4ffc-b5ce-364c4a6fb49f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 80.506\n",
            "Average bias: 80.272\n",
            "Average variance: 0.235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 10, learning_rate = 0.01)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3gVfFYyli3N",
        "outputId": "ec7ff043-7290-4717-9e1b-3aee5e1f498e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 71.001\n",
            "Average bias: 70.750\n",
            "Average variance: 0.251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 100, learning_rate = 0.01)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4GWGGGvln4I",
        "outputId": "7a22559d-c472-4b46-cd33-1cc4e539f0ae"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 30.290\n",
            "Average bias: 29.166\n",
            "Average variance: 1.123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 500, learning_rate = 0.01)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiyOjMWGl1hI",
        "outputId": "e20ca7a4-8422-4494-ff8f-dab5cff9ae01"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 19.407\n",
            "Average bias: 17.115\n",
            "Average variance: 2.292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overfitting and Underfitting"
      ],
      "metadata": {
        "id": "2le0x9rafnyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 1, learning_rate = 0.1)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3JsGcncfrcY",
        "outputId": "8888fbec-ead0-4e13-ef14-862b98d77f70"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 70.558\n",
            "Average bias: 70.295\n",
            "Average variance: 0.263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 500, learning_rate = 0.1)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKHWONoHniRo",
        "outputId": "ee691fc4-ee5a-4c35-dd39-cb1cb93e29fe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 18.317\n",
            "Average bias: 14.507\n",
            "Average variance: 3.809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "model_boosting = lgb.LGBMRegressor(n_estimators = 5000, learning_rate = 0.1)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        model_boosting, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg3BEc3_nmHG",
        "outputId": "0d67bd49-6cce-4a94-9c33-89b85d632a8b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 18.359\n",
            "Average bias: 14.357\n",
            "Average variance: 4.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uJMUZi0noA_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}